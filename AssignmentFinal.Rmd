---
title: "CSML1000-003-O-F19 - Group 2 - Assignment Final"
author: "Rajiv Kaushik, Yuming Cui, Madana Bolla, Pratik Chandwani, Konstantin Krassavine"
date: "111/15/2019"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,echo=FALSE,warning=FALSE,message=FALSE)
```

image: ![](./images/heartdisease.jpg) 
# Modeling Risk of Heart Disease on Patients in Cleveland, OH, USA
Kaggle Repository for this dataset is located at [link](https://www.kaggle.com/ronitf/heart-disease-uci) 

## Problem Statement

Predict heart disease in a patient from Cleveland Medical Center, OH, USA. Since this analysis and modeling covers risk to human life, it is important to maintain a high rate of identifying patients with heart disease (i.e True Positives, therefore high sensitivity) while maintaining a realistic error rate for those who do not have heart disease ( False Positives, redicting heart disease in a patient when there is none) 


## Context

This database contains data about the factors related to heart disease. There are 76 attributes from V.A. Medical Center, Long Beach and Cleveland Clinic Foundation. 
The "target" field refers to the presence of heart disease in the patient. 0 represents "Not a significant risk of heart disease", 1 imlies "Significant risk of heart disease"  


## Content

Attribute Information:
 1. age
 2. sex
 3. chest pain type (4 values)
 4. resting blood pressure
 5. serum cholestoral in mg/dl
 6. fasting blood sugar > 120 mg/dl
 7. resting electrocardiographic results (values 0,1,2)
 8. maximum heart rate achieved
 9. exercise induced angina
 10. oldpeak = ST depression induced by exercise relative to rest
 11. the slope of the peak exercise ST segment
 12. number of major vessels (0-3) colored by flourosopy
 13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect

## Solution Approach TODO
1. Classification problem
2. ..

```{r installpackages}
library(Hmisc)
library(caret)
library(mice)
library(VIM)
library(ggplot2)
library(EnvStats)
library(cluster)
library(corrplot)
library(NbClust)
library(factoextra)
library(knitr)
library(pROC)
library(rpart)
library(rpart.plot)
library(neuralnet)
library(gbm)
library(ROCR)
library(effects)
```

Read data
```{r}
## Load dataset
heart <- read.csv('./data/heart-with-na.csv', header=TRUE, sep = ",")
```

## Summary of overall dataset
```{r}
head(heart, 5)
summary(heart)
```

## Summary of missing data

There are 64% values in the data set with no missing values. There are 15% missing values in age, 10% in fbs, 10% in slope, and 9% in cp.

```{r}
md.pattern(heart)
```


```{r}
### View miss data pattern with VIM

 mice_plot <- aggr(heart, col=c('navyblue','yellow'),
                    numbers=TRUE, sortVars=TRUE,
                    labels=names(heart), cex.axis=.7,
                    gap=3, ylab=c("Missing data","Pattern"))
```

## Data Imputation
Missing data is imputed using predictive mean matching with Mice. Let's sample imputed age and chest pain scale(cp)

```{r}

# Impute missing values
# m  – Refers to 5 imputed data sets
# maxit – Refers to no. of iterations taken to impute missing values
# method – Refers to method used in imputation. we used predictive mean matching.

imputed_Data <- mice(heart, m=5, maxit = 10, method = 'pmm', seed = 500)
imputed_Data
```


```{r}
# TODO change to visual
imputed_Data$imp$age
```


```{r}
# TODO change to visual
imputed_Data$imp$cp
```

```{r}
# combine data back into main dataset
combineData<-complete(imputed_Data)
#summary(combineData)
#md.pattern(combineData)


```


## Visualization of data
Visualize data to see spread, pattern of outliers and scaling needs. We use the Rosner Tests to identify outlier. 
Outcomes are:
1. Needs scaling
2. Four columns have outliers - resting BP (trestbps), Cholesterol (chol), Stress Test depression (oldpeak), Defects (thal)


```{r}
#Melt data
melt_data = melt(combineData, id.vars=c("X"))
#visualize spread of data
ggplot(melt_data,  mapping = aes(x = value)) + geom_bar(fill = "#FF6666") + facet_wrap(~variable, scales = 'free_x')
boxplot(combineData[,-c(1)])
```


```{r}
## Checking outlier
#3 outlier
rosnerTest(combineData$age, k = 4, warn = F)
#3 outlier
rosnerTest(combineData$cp, k = 4, warn = F)
#3 outlier
rosnerTest(combineData$trestbps, k = 4, warn = F)
#0 outliers
rosnerTest(combineData$chol, k = 4, warn = F)
#4 outliers
rosnerTest(combineData$fbs, k = 4, warn = F)
#4 outliers
rosnerTest(combineData$restecg, k = 4, warn = F)
#4 outliers
rosnerTest(combineData$thalach, k = 4, warn = F)
#4 outliers
rosnerTest(combineData$exang, k = 4, warn = F)
#4 outliers
rosnerTest(combineData$oldpeak, k = 4, warn = F)
#4 outliers
rosnerTest(combineData$slope, k = 4, warn = F)
#0 outliers
rosnerTest(combineData$ca, k = 4, warn = F)
#2 outliers
rosnerTest(combineData$thal, k = 4, warn = F)
```

## Data Preparation 
1. Replaced outliers with 5th and 95th percentile values
2. Scale data and visualize post scaling

```{r}
#replace outliers with 5th and 95th percentile values
#remember An outlier is not any point over the 95th percentile 
#or below the 5th percentile. Instead, an outlier is considered so 
#if it is below the first quartile – 1.5·IQR or above third quartile + 1.5·IQR.
capOutlier <- function(x){
   qnt <- quantile(x, probs=c(.25, .75), na.rm = T)
   caps <- quantile(x, probs=c(.05, .95), na.rm = T)
   H <- 1.5 * IQR(x, na.rm = T)
   x[x < (qnt[1] - H)] <- caps[1]
   x[x > (qnt[2] + H)] <- caps[2]
   return(x)
}
combineData$trestbps=capOutlier(combineData$trestbps)
combineData$chol=capOutlier(combineData$chol)
combineData$oldpeak=capOutlier(combineData$oldpeak)
combineData$thal=capOutlier(combineData$thal)


#scale data, and remove rowid and target
data_scaled <- data.frame(scale(combineData[-c(1, 15)]))
#visualize how well data was scaled
boxplot(data_scaled)
#scaling looks good
```


## Data exploration

### Correlation Matrix
Visualize with a correlation matrix how features are correlated with each other and with the target variable. No two columns have a strong correlation (<50%)

```{r}
#corr of data
corrmatrix <- cor(data_scaled)
corrplot(corrmatrix, method = 'number', type="upper")
```


```{r}
#Drop row id
data<- combineData[-c(1)]
```

```{r}

#We explored the different variables in combineData to see which ones were more likes to affect our random forest algorithm.
#names(data)

```


### Pairwise Correlations
Inferences-

1. Male has better change to get heart desease

```{r echo=FALSE}
plot(factor(target) ~ sex, data = data)
title(main="Target by Gender")
```


2. Higher cholestoral is not cleanly correlated with a higher chance of heart desease.

```{r echo=FALSE}
ggplot(data=data, aes(chol, target)) + geom_jitter(height=0.03, alpha=0.2) + stat_smooth(method="loess", alpha=0.2, col="red") + ggtitle("Target By Serum cholestoral in mg/dl") + theme_bw()
```

3. Resting blood presssure does not play a significant role in heart deasease

```{r echo=FALSE}
ggplot(data=data, aes(trestbps, target)) + geom_jitter(height=0.03, alpha=0.2) + stat_smooth(method="loess", alpha=0.2, col="red") + ggtitle("Target By Resting blood pressure") + theme_bw()
```

4. If your heart beat is too high when resting, you should be more careful

```{r echo=FALSE}
ggplot(data=data, aes(thalach, target)) + geom_jitter(height=0.03, alpha=0.2) + stat_smooth(method="loess", alpha=0.2, col="red") + ggtitle("Target By heart rate ") + theme_bw()
```


```{r}
#names(data)
```



## PCA and Reduction of features

We use two methods, princomp and prcomp for PCA. Both show that first 10 features give us 80%-90% of the variance, and that no one variable is overbearing.Due to the high number of principal components relative to input features, we are not reducing any dimensions using PCA.  


```{r}
# ##### Build pca using princomp
data_pca1 <- princomp(data_scaled)
#examine the importance of PCs
summary(data_pca1)
# inspect principal components
# loadings shows variance and and how much each variable contributes to each components
loadings(data_pca1)
fviz_pca_var(data_pca1,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```


```{r}
# ###### using princomp first 10 give us 80% of the variance
# ##### build pca using prcomp
data_pca2 <- prcomp(data_scaled)
summary(data_pca2)
#above shows first 6 account for 88% variance
#plot
plot(data_pca2)
# scree plot
plot(data_pca2, type = "lines")

fviz_pca_var(data_pca2,
             col.var = "contrib", # Color by contributions
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```

## Partition dataset into training (75%) and test(25%) datasets

```{r}
library(caret)
set.seed(3456)
trainingIndex = createDataPartition(data$age, p = 0.75, list=FALSE)
trainData = data[trainingIndex,]
testData = data[-trainingIndex,]
#TODO
nrow(trainData)
```

## Classification and Regression
TODO add overall comment

### Logistic Regression Model
LR Modeling demonstrates that following variables are predictors of target variable - sex,cp, restecg, exang, oldpeak, ca. 
To evaluate and refine the model we take the following steps- 
* Compute average prediction for true outcomes
   + TP are 78%, that is predicting presence of heart disease correctly 78% of the time 
   + TN are 26%, that is predicting no heart disease when there is none 26% of the time
   + 78% is not bad, it can be improved
* ROC curve will help find the threshold
   + We want high TRUE POSITIVES or Sensitivity for diagnosing heart disease, and are ok with higher false positive 
   + Therefore the threshold is at (0.9,0.2) where 90% with heart disease are diagnosed correctly
   + At this the threshold is 0.5. This implies that a probability above 0.5 should be classified as heart disease 
* With 0.5 as threshold, prediction on test dataset leads to sensitivity = 89%
* In order to assess the performance of our model, we will delineate the ROC curve. ROC is also known as Receiver Optimistic Characteristics
   + ROC curve validates that sensitivity is 89.6% 
* Plot the logistic regression model against predictor variables


```{r}
lr.fit <- glm(target~ age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca, data=trainData, family = binomial)
###Shows that the following variables are predictors of target variable
###sex,cp, restecg, exang, oldpeak, ca
summary(lr.fit)
lr.prob=predict(lr.fit,type="response")
summary(lr.prob)
#compute average prediction for true outcomes
#TP are 78%, that is predicting presence of heart disease correctly 78% of the time 
#TN are 26%, that is predicting no heart disease when there is none 26% of the time
#78% is not bad, it can be improved
tapply(lr.prob,trainData$target,mean)
#now we will convert probabilities to predictions using ROC curves
#ROC curve will help find the threshold
lr.predict = prediction(lr.prob, trainData$target)
lr.perf = performance(lr.predict, "tpr", "fpr")
# Plot ROC curve
plot(lr.perf)
# Add colors
plot(lr.perf, colorize=TRUE)
# Add threshold labels 
plot(lr.perf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
#We want high TRUE POSITIVES or Sensitivity for diagnosing heart disease, and are ok with higher false positive 
#Therefore the threshold is at (0.9,0.2) where 90% with heart disease are diagnosed correctly
#At this the threshold is 0.5. This implies that a probability above 0.5 should be classified as heart disease 


#with 0.5 as threshold, lets predict on test dataset
lrtest.prob=predict(lr.fit,type="response", newdata=testData)
#generate confusion matrix 
#Confusion matris shows that model predicts no heart disease for 4 people who have heart disease
#Also predicts heart disease correctly for 35 peoplewho actually have heart disease
table(testData$target,lrtest.prob >= 0.5)
sensitivity = (35/(35+4))*100
# Logistic Regression Model Sensitivity= 89%
# In order to assess the performance of our model, we will delineate the ROC curve. ROC is also known as Receiver Optimistic Characteristics
# ROC curve validates that sensitivity is 89.6% 
auc.lr = roc(testData$target, lrtest.prob, plot = TRUE, col = "blue")
auc.lr


###plot the logistic regression model against predictor variables
# After we have summarised our model, we will visualize it through the following plots
plot(allEffects(lr.fit))


```


### Decision Tree algorithm
```{r}
dt.fit <- rpart(target~ age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca, trainData,method = 'class')
dt.predict <- predict(dt.fit, testData, type = 'class')
dt.probability <- predict(dt.fit, testData, type = 'prob')

rpart.plot(dt.fit)
rpart.plot(dt.fit)
# In order to assess the performance of our model, we will delineate the ROC curve. ROC is also known as Receiver Optimistic Characteristics
# ROC curve shows sensitivity = 82% 
auc.dt = roc(testData$target, factor(dt.predict, ordered = TRUE), plot = TRUE, col = "blue")
auc.dt


```

### Artificial Neural Networks
```{r}
ann.fit =neuralnet(target~ age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca,trainData,linear.output=FALSE)
plot(ann.fit)
ann.predict=compute(ann.fit,testData)
annResult=ann.predict$net.result
#since predicted variable is probabilty and continous, convert to  0 or 1 factor
annResult=ifelse(annResult>0.5,1,0)
auc.ann = roc(testData$target, factor(annResult, ordered = TRUE), plot = TRUE, col = "blue")
auc.ann
```

### Gradient Boosting
This uses ensemble models like weak decision trees. These decision trees combine together to form a strong model of gradient boosting

```{r}
system.time(
gbm.fit <- gbm(target~ age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca
, distribution = "bernoulli"
, data =trainData
, n.trees = 1000
, interaction.depth = 6
, n.minobsinnode = 10
, shrinkage = 0.1
, bag.fraction = 0.5
, train.fraction = nrow(trainData) / (nrow(trainData) + nrow(testData))
)
)
# Determine best iteration based on test data
gbm.iter = gbm.perf(gbm.fit, method = "test")
model.influence = relative.influence(gbm.fit, n.trees = gbm.iter, sort. = TRUE)
#Plot the gbm model
plot(gbm.fit)
# Plot and calculate AUC on test data
gbm.test = predict(gbm.fit, newdata = testData, n.trees = gbm.iter)
auc.gbm = roc(testData$target, gbm.test, plot = TRUE, col = "red")
print(auc.gbm)
auc.gbm
```

